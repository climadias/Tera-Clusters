{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pós-processamento Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure', figsize=(12, 8))\n",
    "import janitor\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "\n",
    "import datetime\n",
    "\n",
    "import sqlite3 as sql\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve\n",
    "\n",
    "\n",
    "#nomalizing data to its std (x_new= x/std(x))\n",
    "from scipy.cluster.vq import whiten\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity=\"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbscan.csv  GMM.csv  HC.csv  kmeans.csv  mean_s.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ./Novo_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"/Novo_02/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmeans=pd.read_csv(\".\"+dir+\"kmeans.csv\", sep=\";\", dtype={\"CPF\":\"object\"})\n",
    "df_mean_s=pd.read_csv(\".\"+dir+\"mean_s.csv\", sep=\";\", dtype={\"CPF\":\"object\"})\n",
    "df_GMM=pd.read_csv(\".\"+dir+\"GMM.csv\", sep=\";\", dtype={\"CPF\":\"object\"})\n",
    "df_dbscan=pd.read_csv(\".\"+dir+\"dbscan.csv\", sep=\";\", dtype={\"CPF\":\"object\"})\n",
    "df_HC=pd.read_csv(\".\"+dir+\"HC.csv\", sep=\";\", dtype={\"CPF\":\"object\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação com ARI Adjusted Rand Score Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusted rand score is 1, as the clustering is exactly the same\n",
    "# df_kmeans, df_mean_s, df_dbscan, df_GMM, df_HC, df_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' objects are mutable, thus they cannot be hashed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-421ce10782b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmod2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlista\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mari\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madjusted_rand_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cluster\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cluster\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mreg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmod2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mari\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mari_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmod1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/R/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m         raise TypeError(\n\u001b[0;32m-> 1799\u001b[0;31m             \u001b[0;34mf\"{repr(type(self).__name__)} objects are mutable, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1800\u001b[0m             \u001b[0;34mf\"thus they cannot be hashed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' objects are mutable, thus they cannot be hashed"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "target=df_HC\n",
    "lista=[df_kmeans,df_mean_s,df_dbscan,df_GMM,df_HC]\n",
    "ari_score={}\n",
    "for mod1 in lista:\n",
    "    reg={}\n",
    "    for mod2 in lista:\n",
    "        ari=adjusted_rand_score(mod1[\"cluster\"].values, mod2[\"cluster\"].values)\n",
    "        reg[mod2]=ari\n",
    "    ari_score[mod1]=reg\n",
    "    print(mod1)\n",
    "    print( reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3ee601ddc596>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmod1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"teste\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmod1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "mod1.name=\"teste\"\n",
    "mod1.name()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de parlamentares\n",
    "con = sql.connect(\"../../dados/sql/base_completa.db\")\n",
    "df=pd.read_sql(\"select * from kpi_cadastro_basico\",con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster=df_kmeans[[\"CPF\",\"cluster\"]].copy()\n",
    "df_cluster.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(df, df_cluster, how=\"left\", on=\"CPF\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"201901\", '201902','201903',\n",
    "                 \"201904\", '201905', '201906', '201907', '201908', '201909',\n",
    "                 '201910', '201911', '201912', '202001', '202002', '202003',\n",
    "                 '202004','202005', '202006', '202007', '202008', '202009'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.info()\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=np.object)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.clf()\n",
    "df.hist(figsize=(10,7))\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas \"somados\" stacked\n",
    "fig = px.histogram(df,x='ORGAO_TOTAL',color=\"cluster\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"ORGAO_TOTAL\",hue=\"cluster\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis= list(df.select_dtypes(include=[np.number]).columns)\n",
    "#variaveis=list(df.columns)\n",
    "target=[\"cluster\"]\n",
    "variaveis\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(variaveis)//2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Histogramas separados overlay!!\n",
    "#fig, ax = plt.subplots(15, 2, figsize=(10, 20))\n",
    "linhas=(len(variaveis)//2)\n",
    "if len(variaveis)%2:\n",
    "    linhas=linhas+1\n",
    "fig, axes = plt.subplots(linhas,2, figsize=(10, 20))\n",
    "bins=10\n",
    "ax=axes.ravel()\n",
    "ficou = df[target] == 0\n",
    "saiu = df[target] == 1\n",
    "i=0\n",
    "for var in variaveis:\n",
    "    #a=df[ficou][var]\n",
    "    #b=df[saiu][var]\n",
    "    ax[i].hist(df[ficou][var],bins=bins, alpha=.5)\n",
    "    ax[i].hist(df[saiu][var],bins=bins, alpha=.5)\n",
    "    ax[i].set_title(var)\n",
    "    #ax[i].yticks(())\n",
    "    ax[i].set_xlabel(\"Feature magnitude\")\n",
    "    ax[i].set_ylabel(\"Frequency\")\n",
    "    ax[i].legend([\"ficou\", \"saiu\"], loc=\"best\")\n",
    "    i+=1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlação=df.corr()\n",
    "correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlação.cluster.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(16, 16))\n",
    "sns.heatmap(correlação,annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.columns\n",
    "variaveis=list(df.columns)\n",
    "target=[\"cluster\"]\n",
    "variaveis\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis\n",
    "target=[\"cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preditores=list(set(variaveis)-set(target))\n",
    "preditores=variaveis\n",
    "variaveis=target+preditores\n",
    "correlação=df[variaveis].corr()\n",
    "correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(12, 8))\n",
    "sns.heatmap(correlação,annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df[variaveis], kind=\"scatter\", hue=target[0])\n",
    "#sns.pairplot(df[variaveis], kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, y_vars=target, x_vars=preditores, hue=target[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Sem ajuste em preditores. Usar todos\n",
    "correlação=df[variaveis].corr()\n",
    "correlação\n",
    "sns.heatmap(correlação,annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fatores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "unicos=df.nunique()\n",
    "unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentar as que tem até 47\n",
    "unicas=5\n",
    "variaveis_categoricas=[]\n",
    "for variavel in unicos.index:\n",
    "    quant=unicos.loc[variavel]\n",
    "    if quant <= unicas:\n",
    "        variaveis_categoricas.append(variavel)\n",
    "        print(\"Variavel {}, {} ocorrências únicas\".format(variavel,quant))\n",
    "        print(df[variavel].sort_values().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left, sales, salary, promotion_last_5years, work_accident\n",
    "\n",
    "variaveis_categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_categoricas.remove(\"ANO_ELEICAO\")\n",
    "variaveis_categoricas.remove(\"DS_CARGO\")\n",
    "variaveis_categoricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[variaveis_categoricas].info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "variaveis_dummy=variaveis_categoricas[0:3]\n",
    "variaveis_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variavel in variaveis_categoricas:\n",
    "    df[variavel]=df[variavel].astype(\"category\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"ANO_ELEICAO\", \"SQ_CANDIDATO\",\"IDADE\",\"ID_CAMARA\",\"LEG_INICIAL\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exibe=['NM_PUBLICO','SG_PARTIDO', 'SG_UE','followers_count', \"ORGAO_TOTAL\",\n",
    "           'ORGAO_PARTICIPANTE','ORGAO_GESTOR', 'PERC_PRESENCA', 'GASTO_GABINETE','cluster']\n",
    "cluster=0\n",
    "sort=\"ORGAO_TOTAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=df[exibe][df[\"cluster\"]==cluster]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_1.groupby(\"SG_PARTIDO\")[\"NM_PUBLICO\"].value_counts()\n",
    "df_contagem=x.unstack().fillna(0)\n",
    "df_contagem[\"TOTAL\"]=df_contagem.sum(axis=1)\n",
    "df_contagem.sort_values(\"TOTAL\", ascending=False, inplace=True)\n",
    "df_contagem=df_contagem[[\"TOTAL\"]].copy()\n",
    "df_1.shape\n",
    "df_contagem=df_contagem.reset_index(drop=False)\n",
    "fig = px.treemap(df_contagem, path=['SG_PARTIDO'], values='TOTAL'\n",
    "                  )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.groupby([\"cluster\",\"SG_PARTIDO\"],as_index=False)[\"SG_PARTIDO\"].sum()\n",
    "x.head()\n",
    "#df_contagem=x.unstack().fillna(0)\n",
    "#df_contagem.head()\n",
    "#df_contagem[\"TOTAL\"]=df_contagem.sum(axis=1)\n",
    "#df_contagem.sort_values(\"TOTAL\", ascending=False, inplace=True)\n",
    "#df_contagem=df_contagem[[\"TOTAL\",\"SG_PARTIDO\"]].copy()\n",
    "#df.shape\n",
    "#df_contagem.head()\n",
    "#df_contagem=df_contagem.reset_index(drop=False)\n",
    "\n",
    "#fig = px.treemap(df_contagem, path=['cluster',\"SG_PARTIDO\"], values='TOTAL')\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_numericas=list(df.select_dtypes(include=[np.number]).columns)\n",
    "variaveis_numericas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variavel in variaveis_categoricas:\n",
    "    df[variavel].value_counts().plot(kind=\"bar\")\n",
    "    plt.xlabel(variavel)\n",
    "    plt.ylabel(\"Contagem\")\n",
    "    plt.title(variavel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exibe=['NM_PUBLICO','SG_PARTIDO', 'SG_UE','followers_count', \"ORGAO_TOTAL\",\n",
    "           'ORGAO_PARTICIPANTE','ORGAO_GESTOR', 'PERC_PRESENCA', 'GASTO_GABINETE','cluster']\n",
    "cluster=1\n",
    "sort=\"ORGAO_TOTAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[exibe][df[\"cluster\"]==cluster].shape\n",
    "df[exibe][df[\"cluster\"]==cluster].sort_values(sort, ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots - Identificando, verificando e tratando outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in variaveis_categoricas:\n",
    "    for num in variaveis_numericas:\n",
    "        sns.boxplot(x=cat, y=num, data=df)\n",
    "        plt.xlabel(cat)\n",
    "        plt.ylabel(num)\n",
    "        plt.title(cat)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# com plotly\n",
    "for cat in variaveis_categoricas:\n",
    "    for num in variaveis_numericas:\n",
    "        #sns.boxplot(x=cat, y=num, data=df)\n",
    "        fig=px.box(df,y=num,x=cat)\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Criação das variáveis dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_categoricas.remove(target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variaveis_categoricas.remove(target[0])\n",
    "#variaveis_dummy.remove(target[0])\n",
    "variaveis_categoricas\n",
    "variaveis_dummy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trata variaveis binárias (0-1)\n",
    "for variavel in variaveis_dummy:\n",
    "    df=pd.concat([df, pd.get_dummies(df[variavel].astype(object), prefix=variavel, drop_first=True)], axis=1)\n",
    "    df.drop(columns=[variavel], inplace=True)\n",
    "df.sample(5)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trata variaveis categóricas\n",
    "variaveis_categoricas=list(set(variaveis_categoricas)-set(variaveis_dummy))\n",
    "for variavel in variaveis_categoricas:\n",
    "    df=pd.concat([df, pd.get_dummies(df[variavel].astype(object), prefix=variavel)], axis=1)\n",
    "    df.drop(columns=[variavel], inplace=True)\n",
    "df.sample(5)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preditores=list(df.select_dtypes(include=[np.number]).columns)\n",
    "target\n",
    "preditores=list(set(preditores)-set(target))\n",
    "preditores\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escala dos preditores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df=df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_escala(preditores,df):\n",
    "    x=df[preditores].values\n",
    "    plt.plot(x.min(axis=0),\"o\", label=\"min\")\n",
    "    plt.plot(x.max(axis=0),\"^\", label=\"max\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Feature index\")\n",
    "    plt.ylabel(\"Feature magnitude\")\n",
    "    plt.yscale(\"log\")\n",
    "    print(df[preditores].max().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifica_escala(preditores, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df[preditores].values)\n",
    "x=scaler.transform(df[preditores].values)\n",
    "df_scaled=pd.DataFrame(x,columns=preditores)\n",
    "df_scaled[target]=df[target]\n",
    "df_scaled.head()\n",
    "df_original=df.copy()\n",
    "df=df_scaled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## treino e teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino, df_teste= train_test_split(df, test_size=0.3, random_state=42, stratify=df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino.shape\n",
    "df_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para classificação de algoritimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificação(modelo,target,preditores,treino,teste):\n",
    "    x_treino=treino[preditores].values\n",
    "    y_treino=treino[target].values\n",
    "    y_treino=y_treino.ravel()\n",
    "    \n",
    "    x_teste=teste[preditores].values\n",
    "    y_teste=teste[target].values\n",
    "    \n",
    "    modelo.fit(x_treino, y_treino)\n",
    "    y_treino_pred=modelo.predict(x_treino)\n",
    "    y_teste_pred=modelo.predict(x_teste)\n",
    "    print(modelo)\n",
    "    plot_confusion_matrix(modelo, x_teste,y_teste, cmap='Blues')\n",
    "    print(\"Acurácia no treino: {:.3f}\".format(modelo.score(x_treino, y_treino)))\n",
    "    print(\"Acuracia no teste: {:.3f}\".format(modelo.score(x_teste, y_teste)))\n",
    "    print(\"Precisão no teste: {:.3f}\".format(precision_score(y_teste, y_teste_pred)))\n",
    "    print(\"Recall no teste: {:.3f}\".format(recall_score(y_teste, y_teste_pred)))\n",
    "    print(\"F1 no teste: {:.3f}\".format(f1_score(y_teste, y_teste_pred)))\n",
    "    plot_roc_curve(modelo, x_teste, y_teste)\n",
    "    mod={}\n",
    "    mod[\"modelo\"]=modelo\n",
    "    mod[\"acuracia_teste\"]=modelo.score(x_teste, y_teste)\n",
    "    mod[\"acuracia_treino\"]=modelo.score(x_treino, y_treino)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore de Decisão "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A árvore de decisão irá classificar novas observações através de simples regras de decisão que terá aprendido com o dataset de treino. Uma característica bem legal desse método é que podemos visualizar a regra de cada nó."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df[preditores].info()\n",
    "df=df.fillna(0)\n",
    "df[preditores].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando a profundidade da árvore e a acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino=df_treino[preditores].values\n",
    "y_treino=df_treino[target].values\n",
    "y_treino=y_treino.ravel()\n",
    "x_teste=df_teste[preditores].values\n",
    "y_teste=df_teste[target].values\n",
    "\n",
    "valores=range(2,50)\n",
    "\n",
    "ac_treino=[]\n",
    "ac_teste=[]\n",
    "    \n",
    "for val in valores:\n",
    "    modelo= DecisionTreeClassifier(max_depth=val)\n",
    "    modelo.fit(x_treino, y_treino)\n",
    "    #y_treino_pred=modelo.predict(x_treino)\n",
    "    #y_teste_pred=modelo.predict(x_teste)\n",
    "    ac_treino.append(modelo.score(x_treino, y_treino))\n",
    "    ac_teste.append(modelo.score(x_teste, y_teste))\n",
    "    \n",
    "df_acuracia=pd.DataFrame({\"Parametro\":valores,\"acuracia_treino\":ac_treino,\"acuracia_teste\":ac_teste }, index=valores) \n",
    "df_acuracia[[\"acuracia_treino\",\"acuracia_teste\"]].plot()\n",
    "df_acuracia.sort_values(\"acuracia_teste\",inplace=True, ascending=False)\n",
    "df_acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "modelo = DecisionTreeClassifier(max_depth=27)\n",
    "\n",
    "result=classificação(modelo,target, preditores, df_treino, df_teste)\n",
    "modelo=result[\"modelo\"]\n",
    "lista_modelos.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando a árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(modelo, feature_names=preditores, filled=True,\n",
    "          class_names=['Fica', 'Sai']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.feature_importances_\n",
    "preditores\n",
    "importancia=pd.Series(modelo.feature_importances_, index=preditores)\n",
    "importancia=importancia.sort_values(ascending=True)\n",
    "importancia.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Support Vector Machine, é um algoritmo que encontra uma linha de separação, ou um hiperplano quando temos mais de duas dimensões, que separa os dados em classes. Essa linha tenta maximizar a distância entre os pontos de cada classe. Veja a imagem ilustrativa"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "By default, C=1 and gamma=1/n_features :\n",
    "While SVMs often perform quite well, they are\n",
    "very sensitive to the settings of the parameters and to the scaling of the data. In par‐\n",
    "ticular, they require all the features to vary on a similar scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando o valor de C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino=df_treino[preditores].values\n",
    "y_treino=df_treino[target].values\n",
    "y_treino=y_treino.ravel()\n",
    "x_teste=df_teste[preditores].values\n",
    "y_teste=df_teste[target].values\n",
    "\n",
    "valores=range(1,35)\n",
    "\n",
    "ac_treino=[]\n",
    "ac_teste=[]\n",
    "    \n",
    "for val in valores:\n",
    "    modelo=  SVC(C=val)\n",
    "    modelo.fit(x_treino, y_treino)\n",
    "    #y_treino_pred=modelo.predict(x_treino)\n",
    "    #y_teste_pred=modelo.predict(x_teste)\n",
    "    ac_treino.append(modelo.score(x_treino, y_treino))\n",
    "    ac_teste.append(modelo.score(x_teste, y_teste))\n",
    "    \n",
    "df_acuracia=pd.DataFrame({\"Parametro\":valores,\"acuracia_treino\":ac_treino,\"acuracia_teste\":ac_teste }, index=valores) \n",
    "df_acuracia[[\"acuracia_treino\",\"acuracia_teste\"]].plot()\n",
    "df_acuracia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando o valor de gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino=df_treino[preditores].values\n",
    "y_treino=df_treino[target].values\n",
    "y_treino=y_treino.ravel()\n",
    "x_teste=df_teste[preditores].values\n",
    "y_teste=df_teste[target].values\n",
    "\n",
    "valores=list(np.arange(0.1,5,0.5))\n",
    "\n",
    "ac_treino=[]\n",
    "ac_teste=[]\n",
    "    \n",
    "for val in valores:\n",
    "    modelo=  SVC(C=30, gamma=val)\n",
    "    modelo.fit(x_treino, y_treino)\n",
    "    #y_treino_pred=modelo.predict(x_treino)\n",
    "    #y_teste_pred=modelo.predict(x_teste)\n",
    "    ac_treino.append(modelo.score(x_treino, y_treino))\n",
    "    ac_teste.append(modelo.score(x_teste, y_teste))\n",
    "    \n",
    "df_acuracia=pd.DataFrame({\"Parametro\":valores,\"acuracia_treino\":ac_treino,\"acuracia_teste\":ac_teste }, index=valores) \n",
    "df_acuracia[[\"acuracia_treino\",\"acuracia_teste\"]].plot()\n",
    "df_acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelo = SVC(C=30, gamma=4.1)\n",
    "\n",
    "\n",
    "result=classificação(modelo,target, preditores, df_treino, df_teste)\n",
    "modelo=result[\"modelo\"]\n",
    "lista_modelos.append(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando todos os modelos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Agora que vimos os principais modelos de classificação segue abaixo um exemplo de como podemos fazer a comparação de todos eles com as métricas que aprendemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara_modelos(lista,target,preditores, teste):\n",
    "    x=df[preditores].values\n",
    "    y=df[target].values\n",
    "    ax = plt.gca()\n",
    "    for i in lista:\n",
    "        modelo=i[\"modelo\"]\n",
    "        plot_roc_curve(modelo, x, y, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compara_modelos(lista_modelos, target, preditores, df_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preditores=list(df.columns)\n",
    "target\n",
    "preditores=list(set(preditores)-set(target))\n",
    "preditores\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_treino=df_treino[preditores].values\n",
    "y_treino=(df_treino[target].values).ravel()\n",
    "y_treino.shape\n",
    "X_treino_bal, y_treino_bal = smote.fit_sample(X_treino, y_treino)\n",
    "X_treino_bal.shape\n",
    "y_treino_bal.shape\n",
    "y_treino_bal=y_treino_bal.reshape((-1,1))\n",
    "y_treino_bal.shape\n",
    "\n",
    "variaveis=preditores+target\n",
    "\n",
    "df_treino_bal=pd.DataFrame(X_treino_bal, columns=preditores)\n",
    "df_treino_bal[target[0]]=y_treino_bal\n",
    "df_treino_bal.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanceado\n",
    "X_treino=df_treino_bal[preditores].values\n",
    "y_treino=(df_treino_bal[target].values).ravel()\n",
    "X_treino.shape\n",
    "y_treino.shape\n",
    "X_teste=df_teste[preditores].values\n",
    "y_teste=np.array(df_teste[target]).ravel()\n",
    "y_treino[1:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You should carefully match the solver and regularization method for several reasons:\n",
    "\n",
    "    'liblinear' solver doesn’t work without regularization.\n",
    "    'newton-cg', 'sag', 'saga', and 'lbfgs' don’t support L1 regularization.\n",
    "    'saga' is the only solver that supports elastic-net regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog_bal = LogisticRegression(solver = 'sag', max_iter = 10000).fit(X_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog_bal.intercept_\n",
    "rlog_bal.coef_.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba= rlog_bal.predict_proba(X_treino).round(3)\n",
    "y_proba[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino_pred=rlog_bal.predict(X_treino)\n",
    "y_treino_pred[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste_rlog=rlog_bal.predict(X_teste)\n",
    "y_teste_rlog[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog_bal.score(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog_bal.score(X_teste, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusão - scklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y, model.predict(x))\n",
    "confusion_matrix(y_treino,y_treino_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rlog_bal, X_treino, y_treino, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rlog_bal, X_teste, y_teste, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do sckit \n",
    "#- Acurácia: % de predições corretas\n",
    "#- Precisão: % de predições corretas dentro da classe positiva\n",
    "#- Recall: % de predições corretas dentro da classe esperada como positiva\n",
    "print(classification_report(y_treino, y_treino_pred, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do sckit \n",
    "#- Acurácia: % de predições corretas\n",
    "#- Precisão: % de predições corretas dentro da classe positiva\n",
    "#- Recall: % de predições corretas dentro da classe esperada como positiva\n",
    "print(classification_report(y_teste, y_teste_rlog, target_names=['No', 'Yes']))\n",
    "print(f'Acurácia:{accuracy_score(y_teste, y_teste_rlog)}\\n\\\n",
    "Precisão:{precision_score(y_teste, y_teste_rlog)}\\n\\\n",
    "Recall:{recall_score(y_teste, y_teste_rlog)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva ROC e AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(rlog_bal, X_teste, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cada observação será classifica de acordo com os seus vizinhos. Se k for igual a 3, a nova observação será compara com os 3 vizinhos mais próximos, a classe que pertencer a maioria desses vizinhos será atribuída à nova observação.\n",
    "\n",
    "Na figura abaixo a nova observação representava pelo círculo verde será classificada como triângulo vermelho, pois é classe majoritária levando em conta os três vizinhos mais próximos, porém se k fosse igual à 5, seria classificada como quadrado azul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_bal = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_bal.fit(X_treino, y_treino)\n",
    "y_teste_knn = knn_bal.predict(X_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(knn_bal, X_teste, y_teste, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Acurácia:{accuracy_score(y_teste, y_teste_knn)}\\n\\\n",
    "Precisão:{precision_score(y_teste, y_teste_knn)}\\n\\\n",
    "Recall:{recall_score(y_teste, y_teste_knn)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(knn_bal, X_teste, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando todos os modelos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Agora que vimos os principais modelos de classificação segue abaixo um exemplo de como podemos fazer a comparação de todos eles com as métricas que aprendemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [rlog_1, knn, rlog_bal, knn_bal]\n",
    "ax = plt.gca()\n",
    "for i in classifiers:\n",
    "    plot_roc_curve(i, X_teste, y_teste, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.info()\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "df.hist(figsize=(10,7))\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "fig = px.scatter(df_2007, x=\"gdpPercap\", y=\"lifeExp\", log_x=True,\n",
    "                 hover_name=\"country\", hover_data=[\"continent\", \"pop\"])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas \"somados\" stacked\n",
    "fig = px.histogram(df,x='satisfaction_level',color=\"left\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"satisfaction_level\",hue=\"left\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis=list(df.columns)\n",
    "target=\"left\"\n",
    "variaveis\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(variaveis)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas separados overlay!!\n",
    "#fig, ax = plt.subplots(15, 2, figsize=(10, 20))\n",
    "linhas=(len(variaveis)//2)\n",
    "if len(variaveis)%2:\n",
    "    linhas=linhas+1\n",
    "fig, axes = plt.subplots(linhas,2, figsize=(10, 20))\n",
    "bins=10\n",
    "ax=axes.ravel()\n",
    "ficou = df[target] == 0\n",
    "saiu = df[target] == 1\n",
    "i=0\n",
    "for var in variaveis:\n",
    "    #a=df[ficou][var]\n",
    "    #b=df[saiu][var]\n",
    "    ax[i].hist(df[ficou][var],bins=bins, alpha=.5)\n",
    "    ax[i].hist(df[saiu][var],bins=bins, alpha=.5)\n",
    "    ax[i].set_title(var)\n",
    "    #ax[i].yticks(())\n",
    "    ax[i].set_xlabel(\"Feature magnitude\")\n",
    "    ax[i].set_ylabel(\"Frequency\")\n",
    "    ax[i].legend([\"ficou\", \"saiu\"], loc=\"best\")\n",
    "    i+=1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Histogramas separados overlay com plotly!!\n",
    "\n",
    "#linhas=(len(variaveis)//2)\n",
    "if len(variaveis)%2:\n",
    "    linhas=linhas+1\n",
    "fig = go.Figure()\n",
    "#bins=10\n",
    "#ax=axes.ravel()\n",
    "ficou = df[target] == 0\n",
    "saiu = df[target] == 1\n",
    "#i=0\n",
    "for var in variaveis:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(x=df[ficou][var]))\n",
    "    fig.add_trace(go.Histogram(x=df[saiu][var]))\n",
    "    # Overlay both histograms\n",
    "    fig.update_layout(barmode='overlay')\n",
    "    # Reduce opacity to see both histograms\n",
    "    fig.update_traces(opacity=0.75)\n",
    "    fig.show()\n",
    "#fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlação=df.corr()\n",
    "correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlação.left.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.rc('figure', figsize=(16, 16))\n",
    "sns.heatmap(correlação,annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "variaveis=list(df.columns)\n",
    "target=[\"left\"]\n",
    "variaveis\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preditores=list(set(variaveis)-set(target))\n",
    "variaveis=target+preditores\n",
    "correlação=df[variaveis].corr()\n",
    "correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(12, 8))\n",
    "sns.heatmap(correlação,annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df[variaveis], kind=\"scatter\", hue=target[0])\n",
    "sns.pairplot(df[variaveis], kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, y_vars=target, x_vars=preditores, hue=target[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Sem ajuste em preditores. Usar todos\n",
    "correlação=df[variaveis].corr()\n",
    "correlação\n",
    "sns.heatmap(correlação,annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fatores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "unicos=df.nunique()\n",
    "unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentar as que tem até 10\n",
    "unicas=10\n",
    "variaveis_categoricas=[]\n",
    "for variavel in unicos.index:\n",
    "    quant=unicos.loc[variavel]\n",
    "    if quant <= unicas:\n",
    "        variaveis_categoricas.append(variavel)\n",
    "        print(\"Variavel {}, {} ocorrências únicas\".format(variavel,quant))\n",
    "        print(df[variavel].sort_values().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left, sales, salary, promotion_last_5years, work_accident\n",
    "\n",
    "variaveis_categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_categoricas.remove(\"number_project\")\n",
    "variaveis_categoricas.remove(\"time_spend_company\")\n",
    "variaveis_categoricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[variaveis_categoricas].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_dummy=variaveis_categoricas[0:3]\n",
    "variaveis_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variavel in variaveis_categoricas:\n",
    "    df[variavel]=df[variavel].astype(\"category\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_numericas=list((df.columns))\n",
    "variaveis_numericas=list(set(variaveis_numericas)-set(variaveis_categoricas))\n",
    "variaveis_numericas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variavel in variaveis_categoricas:\n",
    "    df[variavel].value_counts().plot(kind=\"bar\")\n",
    "    plt.xlabel(variavel)\n",
    "    plt.ylabel(\"Contagem\")\n",
    "    plt.title(variavel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots - Identificando, verificando e tratando outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in variaveis_categoricas:\n",
    "    for num in variaveis_numericas:\n",
    "        sns.boxplot(x=cat, y=num, data=df)\n",
    "        plt.xlabel(cat)\n",
    "        plt.ylabel(num)\n",
    "        plt.title(cat)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# com plotly\n",
    "for cat in variaveis_categoricas:\n",
    "    for num in variaveis_numericas:\n",
    "        #sns.boxplot(x=cat, y=num, data=df)\n",
    "        fig=px.box(df,y=num,x=cat)\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Criação das variáveis dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_categoricas.remove(target[0])\n",
    "variaveis_dummy.remove(target[0])\n",
    "variaveis_categoricas\n",
    "variaveis_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trata variaveis binárias (0-1)\n",
    "for variavel in variaveis_dummy:\n",
    "    df=pd.concat([df, pd.get_dummies(df[variavel].astype(object), prefix=variavel, drop_first=True)], axis=1)\n",
    "    df.drop(columns=[variavel], inplace=True)\n",
    "df.sample(5)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trata variaveis categóricas\n",
    "variaveis_categoricas=list(set(variaveis_categoricas)-set(variaveis_dummy))\n",
    "for variavel in variaveis_categoricas:\n",
    "    df=pd.concat([df, pd.get_dummies(df[variavel].astype(object), prefix=variavel)], axis=1)\n",
    "    df.drop(columns=[variavel], inplace=True)\n",
    "df.sample(5)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preditores=list(df.columns)\n",
    "target\n",
    "preditores=list(set(preditores)-set(target))\n",
    "preditores\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escala dos preditores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_escala(preditores,df):\n",
    "    x=df[preditores].values\n",
    "    plt.plot(x.min(axis=0),\"o\", label=\"min\")\n",
    "    plt.plot(x.max(axis=0),\"^\", label=\"max\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Feature index\")\n",
    "    plt.ylabel(\"Feature magnitude\")\n",
    "    #plt.yscale(\"log\")\n",
    "    print(df[preditores].max().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifica_escala(preditores, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df[preditores].values)\n",
    "x=scaler.transform(df[preditores].values)\n",
    "df_scaled=pd.DataFrame(x,columns=preditores)\n",
    "df_scaled[target]=df[target]\n",
    "df_scaled.head()\n",
    "df_original=df.copy()\n",
    "df=df_scaled.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## treino e teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino, df_teste= train_test_split(df, test_size=0.3, random_state=42, stratify=df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino.shape\n",
    "df_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão logística - statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preditores=list(df.columns)\n",
    "target\n",
    "preditores=list(set(preditores)-set(target))\n",
    "preditores\n",
    "target"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "However, StatsModels doesn’t take the intercept 𝑏₀ into account, and you need to include the additional column of ones in x. You do that with add_constant():"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Balanceado\n",
    "X_treino=df_treino_bal[preditores].values\n",
    "X_treino=sm.add_constant(X_treino)\n",
    "\n",
    "y_treino=df_treino_bal[target].values\n",
    "y_treino=y_treino.ravel()\n",
    "\n",
    "X_teste=df_teste[preditores].values\n",
    "X_teste=sm.add_constant(X_teste)\n",
    "y_teste=df_teste[target].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Não Balanceado\n",
    "X_treino=df_treino[preditores].values\n",
    "X_treino=sm.add_constant(X_treino)\n",
    "y_treino=df_treino[target].values\n",
    "#y_treino=y_treino.ravel()\n",
    "\n",
    "X_teste=df_teste[preditores].values\n",
    "X_teste=sm.add_constant(X_teste)\n",
    "y_teste=df_teste[target].values\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note that the first argument here is y, followed by x.\n",
    "Now, you’ve created your model and you should fit it with the existing data. You do that with .fit() or, if you want to apply L1 regularization, with .fit_regularized():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#est = sm.Logit(y_train.ravel(), X_train).fit()\n",
    "#Note that the first argument here is y, followed by x.\n",
    "rlog_1= sm.Logit(y_treino, X_treino).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog_1.summary()\n",
    "rlog_1.summary2()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# retirar preditores X3,X5, X7, X8, X9, X10, X11, X13,X14,X15,X16,X17, X18\n",
    "#preditores.pop(2,4,6,7,8,9,10,12,13,14,15,16,17)\n",
    "preditores.pop(17)\n",
    "preditores.pop(16)\n",
    "preditores.pop(15)\n",
    "preditores.pop(14)\n",
    "preditores.pop(13)\n",
    "preditores.pop(12)\n",
    "preditores.pop(10)\n",
    "preditores.pop(9)\n",
    "preditores.pop(8)\n",
    "preditores.pop(7)\n",
    "preditores.pop(6)\n",
    "preditores.pop(2)\n",
    "preditores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#est = sm.Logit(y_train.ravel(), X_train).fit()\n",
    "#Note that the first argument here is y, followed by x.\n",
    "X_treino=df_treino[preditores].values\n",
    "X_treino=\n",
    "rlog_1= sm.Logit(y_treino, X_treino).fit()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rlog_1.summary()\n",
    "rlog_1.summary2()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You can use results to obtain the probabilities of the predicted outputs being equal to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba=rlog_1.predict(X_treino).round(3)\n",
    "y_proba[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predição treino\n",
    "y_treino_pred=(rlog_1.predict(X_treino) >= 0.5).astype(int)\n",
    "y_treino_pred[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predição teste\n",
    "y_teste_pred=(rlog_1.predict(X_teste) >= 0.5).astype(int)\n",
    "y_teste_pred[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusão - statsmodel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You can obtain the confusion matrix with .pred_table():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_conf=rlog_1.pred_table()\n",
    "matriz_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para statsmodels\n",
    "#cm = confusion_matrix(y, model.predict(x))\n",
    "\n",
    "def plot_matriz_confusão(cm):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matriz_confusão(matriz_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do sckit \n",
    "#- Acurácia: % de predições corretas\n",
    "#- Precisão: % de predições corretas dentro da classe positiva\n",
    "#- Recall: % de predições corretas dentro da classe esperada como positiva\n",
    "print(classification_report(y_treino, y_treino_pred, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_teste, y_teste_pred, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão logística - sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preditores\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Não balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não balanceado\n",
    "X_treino=df_treino[preditores].values\n",
    "y_treino=(df_treino[target].values).ravel()\n",
    "\n",
    "X_treino.shape\n",
    "y_treino.shape\n",
    "X_teste=df_teste[preditores].values\n",
    "y_teste=np.array(df_teste[target]).ravel()\n",
    "y_treino[1:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You should carefully match the solver and regularization method for several reasons:\n",
    "\n",
    "    'liblinear' solver doesn’t work without regularization.\n",
    "    'newton-cg', 'sag', 'saga', and 'lbfgs' don’t support L1 regularization.\n",
    "    'saga' is the only solver that supports elastic-net regularization.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If your data consists of hundreds of thou‐\n",
    "sands or millions of samples, you might want to investigate using the solver='sag'\n",
    "option in LogisticRegression and Ridge , which can be faster than the default on\n",
    "large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog_1 = LogisticRegression(solver = 'sag', max_iter = 10000)\n",
    "rlog_1.fit(X_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog_1.intercept_\n",
    "rlog_1.coef_.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba= rlog_1.predict_proba(X_treino).round(3)\n",
    "y_proba[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino_pred=rlog_1.predict(X_treino)\n",
    "y_treino_pred[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste_rlog=rlog_1.predict(X_teste)\n",
    "y_teste_rlog[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog_1.score(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog_1.score(X_teste, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusão - scklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y, model.predict(x))\n",
    "confusion_matrix(y_treino,y_treino_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rlog_1, X_treino, y_treino, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rlog_1, X_teste, y_teste, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do sckit \n",
    "#- Acurácia: % de predições corretas\n",
    "#- Precisão: % de predições corretas dentro da classe positiva\n",
    "#- Recall: % de predições corretas dentro da classe esperada como positiva\n",
    "print(classification_report(y_treino, y_treino_pred, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do sckit \n",
    "#- Acurácia: % de predições corretas\n",
    "#- Precisão: % de predições corretas dentro da classe positiva\n",
    "#- Recall: % de predições corretas dentro da classe esperada como positiva\n",
    "print(classification_report(y_teste, y_teste_rlog, target_names=['No', 'Yes']))\n",
    "print(f'Acurácia:{accuracy_score(y_teste, y_teste_rlog)}\\n\\\n",
    "Precisão:{precision_score(y_teste, y_teste_rlog)}\\n\\\n",
    "Recall:{recall_score(y_teste, y_teste_rlog)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva ROC e AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(rlog_1, X_teste, y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificação(modelo,target,preditores,treino,teste):\n",
    "    x_treino=treino[preditores].values\n",
    "    y_treino=treino[target].values\n",
    "    y_treino=y_treino.ravel()\n",
    "    \n",
    "    x_teste=teste[preditores].values\n",
    "    y_teste=teste[target].values\n",
    "    \n",
    "    modelo.fit(x_treino, y_treino)\n",
    "    y_treino_pred=modelo.predict(x_treino)\n",
    "    y_teste_pred=modelo.predict(x_teste)\n",
    "    print(modelo)\n",
    "    plot_confusion_matrix(modelo, x_teste,y_teste, cmap='Blues')\n",
    "    print(\"Acurácia no treino: {:.3f}\".format(modelo.score(x_treino, y_treino)))\n",
    "    print(\"Acuracia no teste: {:.3f}\".format(modelo.score(x_teste, y_teste)))\n",
    "    print(\"Precisão no teste: {:.3f}\".format(precision_score(y_teste, y_teste_pred)))\n",
    "    print(\"Recall no teste: {:.3f}\".format(recall_score(y_teste, y_teste_pred)))\n",
    "    print(\"F1 no teste: {:.3f}\".format(f1_score(y_teste, y_teste_pred)))\n",
    "    plot_roc_curve(modelo, x_teste, y_teste)\n",
    "    mod={}\n",
    "    mod[\"modelo\"]=modelo\n",
    "    mod[\"acuracia_teste\"]=modelo.score(x_teste, y_teste)\n",
    "    mod[\"acuracia_treino\"]=modelo.score(x_treino, y_treino)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_modelos=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelo=LogisticRegression(solver = 'sag', max_iter = 10000, random_state=42)\n",
    "\n",
    "result=classificação(modelo,target, preditores, df_treino, df_teste)\n",
    "modelo=result[\"modelo\"]\n",
    "lista_modelos.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN - verificando o valor de K ideal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando o número e a acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino=df_treino[preditores].values\n",
    "y_treino=df_treino[target].values\n",
    "y_treino=y_treino.ravel()\n",
    "x_teste=df_teste[preditores].values\n",
    "y_teste=df_teste[target].values\n",
    "\n",
    "valores=range(1,10)\n",
    "\n",
    "ac_treino=[]\n",
    "ac_teste=[]\n",
    "    \n",
    "for val in valores:\n",
    "    modelo= KNeighborsClassifier(n_neighbors=val)\n",
    "    modelo.fit(x_treino, y_treino)\n",
    "    #y_treino_pred=modelo.predict(x_treino)\n",
    "    #y_teste_pred=modelo.predict(x_teste)\n",
    "    ac_treino.append(modelo.score(x_treino, y_treino))\n",
    "    ac_teste.append(modelo.score(x_teste, y_teste))\n",
    "    \n",
    "df_acuracia=pd.DataFrame({\"Parametro\":valores,\"acuracia_treino\":ac_treino,\"acuracia_teste\":ac_teste }, index=valores) \n",
    "df_acuracia[[\"acuracia_treino\",\"acuracia_teste\"]].plot()\n",
    "df_acuracia"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cada observação será classifica de acordo com os seus vizinhos. Se k for igual a 3, a nova observação será compara com os 3 vizinhos mais próximos, a classe que pertencer a maioria desses vizinhos será atribuída à nova observação.\n",
    "\n",
    "Na figura abaixo a nova observação representava pelo círculo verde será classificada como triângulo vermelho, pois é classe majoritária levando em conta os três vizinhos mais próximos, porém se k fosse igual à 5, seria classificada como quadrado azul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "result=classificação(modelo,target, preditores, df_treino, df_teste)\n",
    "modelo=result[\"modelo\"]\n",
    "lista_modelos.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore de Decisão "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A árvore de decisão irá classificar novas observações através de simples regras de decisão que terá aprendido com o dataset de treino. Uma característica bem legal desse método é que podemos visualizar a regra de cada nó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando a profundidade da árvore e a acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino=df_treino[preditores].values\n",
    "y_treino=df_treino[target].values\n",
    "y_treino=y_treino.ravel()\n",
    "x_teste=df_teste[preditores].values\n",
    "y_teste=df_teste[target].values\n",
    "\n",
    "valores=range(2,15)\n",
    "\n",
    "ac_treino=[]\n",
    "ac_teste=[]\n",
    "    \n",
    "for val in valores:\n",
    "    modelo= DecisionTreeClassifier(max_depth=val)\n",
    "    modelo.fit(x_treino, y_treino)\n",
    "    #y_treino_pred=modelo.predict(x_treino)\n",
    "    #y_teste_pred=modelo.predict(x_teste)\n",
    "    ac_treino.append(modelo.score(x_treino, y_treino))\n",
    "    ac_teste.append(modelo.score(x_teste, y_teste))\n",
    "    \n",
    "df_acuracia=pd.DataFrame({\"Parametro\":valores,\"acuracia_treino\":ac_treino,\"acuracia_teste\":ac_teste }, index=valores) \n",
    "df_acuracia[[\"acuracia_treino\",\"acuracia_teste\"]].plot()\n",
    "df_acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "modelo = DecisionTreeClassifier(max_depth=9)\n",
    "\n",
    "result=classificação(modelo,target, preditores, df_treino, df_teste)\n",
    "modelo=result[\"modelo\"]\n",
    "lista_modelos.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando a árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(modelo, feature_names=preditores, filled=True,\n",
    "          class_names=['Fica', 'Sai']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.feature_importances_\n",
    "preditores\n",
    "importancia=pd.Series(modelo.feature_importances_, index=preditores)\n",
    "importancia=importancia.sort_values(ascending=True)\n",
    "importancia.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Support Vector Machine, é um algoritmo que encontra uma linha de separação, ou um hiperplano quando temos mais de duas dimensões, que separa os dados em classes. Essa linha tenta maximizar a distância entre os pontos de cada classe. Veja a imagem ilustrativa"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "By default, C=1 and gamma=1/n_features :\n",
    "While SVMs often perform quite well, they are\n",
    "very sensitive to the settings of the parameters and to the scaling of the data. In par‐\n",
    "ticular, they require all the features to vary on a similar scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando o valor de C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino=df_treino[preditores].values\n",
    "y_treino=df_treino[target].values\n",
    "y_treino=y_treino.ravel()\n",
    "x_teste=df_teste[preditores].values\n",
    "y_teste=df_teste[target].values\n",
    "\n",
    "valores=range(1,35)\n",
    "\n",
    "ac_treino=[]\n",
    "ac_teste=[]\n",
    "    \n",
    "for val in valores:\n",
    "    modelo=  SVC(C=val)\n",
    "    modelo.fit(x_treino, y_treino)\n",
    "    #y_treino_pred=modelo.predict(x_treino)\n",
    "    #y_teste_pred=modelo.predict(x_teste)\n",
    "    ac_treino.append(modelo.score(x_treino, y_treino))\n",
    "    ac_teste.append(modelo.score(x_teste, y_teste))\n",
    "    \n",
    "df_acuracia=pd.DataFrame({\"Parametro\":valores,\"acuracia_treino\":ac_treino,\"acuracia_teste\":ac_teste }, index=valores) \n",
    "df_acuracia[[\"acuracia_treino\",\"acuracia_teste\"]].plot()\n",
    "df_acuracia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando o valor de gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino=df_treino[preditores].values\n",
    "y_treino=df_treino[target].values\n",
    "y_treino=y_treino.ravel()\n",
    "x_teste=df_teste[preditores].values\n",
    "y_teste=df_teste[target].values\n",
    "\n",
    "valores=list(np.arange(0.1,5,0.5))\n",
    "\n",
    "ac_treino=[]\n",
    "ac_teste=[]\n",
    "    \n",
    "for val in valores:\n",
    "    modelo=  SVC(C=30, gamma=val)\n",
    "    modelo.fit(x_treino, y_treino)\n",
    "    #y_treino_pred=modelo.predict(x_treino)\n",
    "    #y_teste_pred=modelo.predict(x_teste)\n",
    "    ac_treino.append(modelo.score(x_treino, y_treino))\n",
    "    ac_teste.append(modelo.score(x_teste, y_teste))\n",
    "    \n",
    "df_acuracia=pd.DataFrame({\"Parametro\":valores,\"acuracia_treino\":ac_treino,\"acuracia_teste\":ac_teste }, index=valores) \n",
    "df_acuracia[[\"acuracia_treino\",\"acuracia_teste\"]].plot()\n",
    "df_acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelo = SVC(C=30, gamma=4.1)\n",
    "\n",
    "\n",
    "result=classificação(modelo,target, preditores, df_treino, df_teste)\n",
    "modelo=result[\"modelo\"]\n",
    "lista_modelos.append(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando todos os modelos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Agora que vimos os principais modelos de classificação segue abaixo um exemplo de como podemos fazer a comparação de todos eles com as métricas que aprendemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara_modelos(lista,target,preditores, teste):\n",
    "    x=df[preditores].values\n",
    "    y=df[target].values\n",
    "    ax = plt.gca()\n",
    "    for i in lista:\n",
    "        modelo=i[\"modelo\"]\n",
    "        plot_roc_curve(modelo, x, y, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compara_modelos(lista_modelos, target, preditores, df_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preditores=list(df.columns)\n",
    "target\n",
    "preditores=list(set(preditores)-set(target))\n",
    "preditores\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_treino=df_treino[preditores].values\n",
    "y_treino=(df_treino[target].values).ravel()\n",
    "y_treino.shape\n",
    "X_treino_bal, y_treino_bal = smote.fit_sample(X_treino, y_treino)\n",
    "X_treino_bal.shape\n",
    "y_treino_bal.shape\n",
    "y_treino_bal=y_treino_bal.reshape((-1,1))\n",
    "y_treino_bal.shape\n",
    "\n",
    "variaveis=preditores+target\n",
    "\n",
    "df_treino_bal=pd.DataFrame(X_treino_bal, columns=preditores)\n",
    "df_treino_bal[target[0]]=y_treino_bal\n",
    "df_treino_bal.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanceado\n",
    "X_treino=df_treino_bal[preditores].values\n",
    "y_treino=(df_treino_bal[target].values).ravel()\n",
    "X_treino.shape\n",
    "y_treino.shape\n",
    "X_teste=df_teste[preditores].values\n",
    "y_teste=np.array(df_teste[target]).ravel()\n",
    "y_treino[1:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You should carefully match the solver and regularization method for several reasons:\n",
    "\n",
    "    'liblinear' solver doesn’t work without regularization.\n",
    "    'newton-cg', 'sag', 'saga', and 'lbfgs' don’t support L1 regularization.\n",
    "    'saga' is the only solver that supports elastic-net regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog_bal = LogisticRegression(solver = 'sag', max_iter = 10000).fit(X_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog_bal.intercept_\n",
    "rlog_bal.coef_.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba= rlog_bal.predict_proba(X_treino).round(3)\n",
    "y_proba[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino_pred=rlog_bal.predict(X_treino)\n",
    "y_treino_pred[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste_rlog=rlog_bal.predict(X_teste)\n",
    "y_teste_rlog[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog_bal.score(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog_bal.score(X_teste, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusão - scklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y, model.predict(x))\n",
    "confusion_matrix(y_treino,y_treino_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rlog_bal, X_treino, y_treino, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rlog_bal, X_teste, y_teste, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do sckit \n",
    "#- Acurácia: % de predições corretas\n",
    "#- Precisão: % de predições corretas dentro da classe positiva\n",
    "#- Recall: % de predições corretas dentro da classe esperada como positiva\n",
    "print(classification_report(y_treino, y_treino_pred, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do sckit \n",
    "#- Acurácia: % de predições corretas\n",
    "#- Precisão: % de predições corretas dentro da classe positiva\n",
    "#- Recall: % de predições corretas dentro da classe esperada como positiva\n",
    "print(classification_report(y_teste, y_teste_rlog, target_names=['No', 'Yes']))\n",
    "print(f'Acurácia:{accuracy_score(y_teste, y_teste_rlog)}\\n\\\n",
    "Precisão:{precision_score(y_teste, y_teste_rlog)}\\n\\\n",
    "Recall:{recall_score(y_teste, y_teste_rlog)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva ROC e AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(rlog_bal, X_teste, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cada observação será classifica de acordo com os seus vizinhos. Se k for igual a 3, a nova observação será compara com os 3 vizinhos mais próximos, a classe que pertencer a maioria desses vizinhos será atribuída à nova observação.\n",
    "\n",
    "Na figura abaixo a nova observação representava pelo círculo verde será classificada como triângulo vermelho, pois é classe majoritária levando em conta os três vizinhos mais próximos, porém se k fosse igual à 5, seria classificada como quadrado azul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_bal = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_bal.fit(X_treino, y_treino)\n",
    "y_teste_knn = knn_bal.predict(X_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(knn_bal, X_teste, y_teste, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Acurácia:{accuracy_score(y_teste, y_teste_knn)}\\n\\\n",
    "Precisão:{precision_score(y_teste, y_teste_knn)}\\n\\\n",
    "Recall:{recall_score(y_teste, y_teste_knn)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(knn_bal, X_teste, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando todos os modelos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Agora que vimos os principais modelos de classificação segue abaixo um exemplo de como podemos fazer a comparação de todos eles com as métricas que aprendemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [rlog_1, knn, rlog_bal, knn_bal]\n",
    "ax = plt.gca()\n",
    "for i in classifiers:\n",
    "    plot_roc_curve(i, X_teste, y_teste, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.fillna(0, inplace=True)\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=np.object)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.clf()\n",
    "df.hist(figsize=(10,7))\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "unicos=df.nunique()\n",
    "unicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defindo variaveis categóricas numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisa_variaveis(df,variaveis,nunicas):\n",
    "    lista=[]\n",
    "    unicos=df[variaveis].nunique()\n",
    "    for variavel in unicos.index:\n",
    "        quant=unicos.loc[variavel]\n",
    "        if quant <= nunicas:\n",
    "            lista.append(variavel)\n",
    "            print(\"Variavel {}, {} ocorrências únicas\".format(variavel,quant))\n",
    "            print(df[variavel].sort_values().unique())\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_numericas= df.select_dtypes(include=[np.number]).columns\n",
    "variaveis_categoricas= df.select_dtypes(include=\"category\").columns\n",
    "df[variaveis_numericas].info()\n",
    "df[variaveis_categoricas].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_objeto=df.select_dtypes(include=\"object\").columns\n",
    "df[variaveis_objeto].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variavel in variaveis_categoricas:\n",
    "    df[variavel].value_counts().plot(kind=\"bar\")\n",
    "    plt.xlabel(variavel)\n",
    "    plt.ylabel(\"Contagem\")\n",
    "    plt.title(variavel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots - Identificando, verificando e tratando outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in variaveis_categoricas:\n",
    "    for num in variaveis_numericas:\n",
    "        sns.boxplot(x=cat, y=num, data=df)\n",
    "        plt.xlabel(cat)\n",
    "        plt.ylabel(num)\n",
    "        plt.title(cat)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis=list(variaveis_numericas)+list(variaveis_categoricas)\n",
    "variaveis.remove(\"cluster\")\n",
    "preditores=variaveis\n",
    "target=[\"cluster\"]\n",
    "variaveis=[\"cluster\"]+variaveis\n",
    "variaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"cluster\"]=df[\"cluster\"].astype(\"int\")\n",
    "df[\"cluster\"]=df[\"cluster\"].astype(\"int\")\n",
    "df[\"cluster\"]=df[\"cluster\"].astype(\"int\")\n",
    "df[\"cluster\"]=df[\"cluster\"].astype(\"int\")\n",
    "df[\"cluster\"]=df[\"cluster\"].astype(\"int\")\n",
    "\n",
    "correlação=df[variaveis].corr()\n",
    "correlação\n",
    "plt.rc('figure', figsize=(12, 8))\n",
    "sns.heatmap(correlação,annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[variaveis], kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, y_vars=target, x_vars=preditores, hue=target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusted rand score is 1, as the clustering is exactly the same\n",
    "# df_kmeans, df_mean_s, df_dbscan, df_GMM, df_HC, df_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "target=df_HC\n",
    "lista=[df_kmeans,df_mean_s,df_dbscan,df_GMM,df_HC,df_ch]\n",
    "\n",
    "for df in lista:\n",
    "    print(\"ARI: {:.2f}\".format(adjusted_rand_score(target[\"cluster\"].values, df[\"cluster\"].values)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA com K-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_HC.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.fillna(0, inplace=True)\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=np.object)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.clf()\n",
    "df.hist(figsize=(10,7))\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "unicos=df.nunique()\n",
    "unicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defindo variaveis categóricas numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisa_variaveis(df,variaveis,nunicas):\n",
    "    lista=[]\n",
    "    unicos=df[variaveis].nunique()\n",
    "    for variavel in unicos.index:\n",
    "        quant=unicos.loc[variavel]\n",
    "        if quant <= nunicas:\n",
    "            lista.append(variavel)\n",
    "            print(\"Variavel {}, {} ocorrências únicas\".format(variavel,quant))\n",
    "            print(df[variavel].sort_values().unique())\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_numericas= df.select_dtypes(include=[np.number]).columns\n",
    "variaveis_categoricas= df.select_dtypes(include=\"category\").columns\n",
    "df[variaveis_numericas].info()\n",
    "df[variaveis_categoricas].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_objeto=df.select_dtypes(include=\"object\").columns\n",
    "df[variaveis_objeto].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variavel in variaveis_categoricas:\n",
    "    df[variavel].value_counts().plot(kind=\"bar\")\n",
    "    plt.xlabel(variavel)\n",
    "    plt.ylabel(\"Contagem\")\n",
    "    plt.title(variavel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots - Identificando, verificando e tratando outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in variaveis_categoricas:\n",
    "    for num in variaveis_numericas:\n",
    "        sns.boxplot(x=cat, y=num, data=df)\n",
    "        plt.xlabel(cat)\n",
    "        plt.ylabel(num)\n",
    "        plt.title(cat)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis=list(variaveis_numericas)+list(variaveis_categoricas)\n",
    "variaveis.remove(\"cluster\")\n",
    "preditores=variaveis\n",
    "target=[\"cluster\"]\n",
    "variaveis=[\"cluster\"]+variaveis\n",
    "variaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"cluster\"]=df[\"cluster\"].astype(\"int\")\n",
    "df[\"cluster\"]=df[\"cluster\"].astype(\"int\")\n",
    "df[\"cluster\"]=df[\"cluster\"].astype(\"int\")\n",
    "df[\"cluster\"]=df[\"cluster\"].astype(\"int\")\n",
    "df[\"cluster\"]=df[\"cluster\"].astype(\"int\")\n",
    "\n",
    "correlação=df[variaveis].corr()\n",
    "correlação\n",
    "plt.rc('figure', figsize=(12, 8))\n",
    "sns.heatmap(correlação,annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[variaveis], kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, y_vars=target, x_vars=preditores, hue=target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
